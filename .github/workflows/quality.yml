name: Quality Assurance

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run quality checks weekly on Mondays at 9 AM UTC
    - cron: '0 9 * * 1'

env:
  UV_CACHE_DIR: /tmp/.uv-cache

jobs:
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install

      - name: Install dependencies
        run: uv sync --locked --all-extras --dev

      - name: Run comprehensive linting
        run: |
          echo "🔍 Running ruff checks..."
          uv run ruff check . --output-format=github
          
          echo "🎨 Running black formatting check..."
          uv run black --check --diff .
          
          echo "📏 Running line length check..."
          find . -name "*.py" -not -path "./tests/*" | xargs wc -L | awk '$1 > 88 {print "Line too long in " $2 ": " $1 " characters"; exit 1}'

      - name: Run comprehensive type checking
        run: |
          echo "🔍 Running mypy type checking..."
          uv run mypy chunkhound/ --show-error-codes --pretty
          
          echo "🔍 Running mypy on tests (less strict)..."
          uv run mypy tests/ --ignore-missing-imports --show-error-codes --pretty || true

      - name: Check import sorting
        run: |
          echo "📚 Verifying import sorting..."
          uv run ruff check --select I --diff .

      - name: Check for common security issues
        run: |
          echo "🔒 Checking for hardcoded secrets..."
          # Check for potential API keys or secrets
          if grep -r -i "api[_-]key\s*=\s*['\"][^'\"]*['\"]" --include="*.py" .; then
            echo "❌ Found potential hardcoded API keys"
            exit 1
          fi
          
          echo "🔒 Checking for TODO/FIXME items..."
          # List TODO/FIXME items but don't fail
          grep -r -n "TODO\|FIXME\|XXX" --include="*.py" . || echo "✅ No TODO/FIXME items found"

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install

      - name: Install dependencies
        run: uv sync --locked --all-extras --dev

      - name: Run safety check
        run: |
          echo "🛡️ Running safety check for known vulnerabilities..."
          uv run pip list --format=freeze | uv run safety check --stdin || echo "⚠️ Safety check completed with warnings"

      - name: Check for vulnerable dependencies
        run: |
          echo "🔍 Checking for known vulnerable packages..."
          # Check if any dependencies have known security issues
          uv run pip audit --desc --format=json > audit_results.json || true
          
          # Display results in a readable format
          if [ -f audit_results.json ] && [ -s audit_results.json ]; then
            echo "📋 Security audit results:"
            cat audit_results.json
          else
            echo "✅ No security vulnerabilities found"
          fi

  documentation:
    name: Documentation Quality
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install

      - name: Install dependencies
        run: uv sync --locked --all-extras --dev

      - name: Check docstring coverage
        run: |
          echo "📚 Checking docstring coverage..."
          # Check for missing docstrings in public functions and classes
          uv run python -c "
          import ast
          import os
          
          def check_docstrings(filepath):
              with open(filepath, 'r') as f:
                  content = f.read()
              
              tree = ast.parse(content)
              issues = []
              
              for node in ast.walk(tree):
                  if isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef)):
                      if not node.name.startswith('_'):  # Public methods/classes only
                          if not ast.get_docstring(node):
                              issues.append(f'{filepath}:{node.lineno}: Missing docstring for {node.name}')
              
              return issues
          
          all_issues = []
          for root, dirs, files in os.walk('chunkhound'):
              # Skip __pycache__ directories
              dirs[:] = [d for d in dirs if d != '__pycache__']
              for file in files:
                  if file.endswith('.py'):
                      filepath = os.path.join(root, file)
                      all_issues.extend(check_docstrings(filepath))
          
          if all_issues:
              print('⚠️ Missing docstrings:')
              for issue in all_issues[:10]:  # Show first 10 issues
                  print(f'  {issue}')
              if len(all_issues) > 10:
                  print(f'  ... and {len(all_issues) - 10} more')
          else:
              print('✅ All public functions and classes have docstrings')
          "

      - name: Validate README and documentation
        run: |
          echo "📖 Validating README.md..."
          if [ ! -f README.md ]; then
            echo "❌ README.md not found"
            exit 1
          fi
          
          # Check for basic sections in README
          for section in "Installation" "Usage" "Features"; do
            if ! grep -i "##.*$section" README.md; then
              echo "⚠️ Missing $section section in README.md"
            fi
          done
          
          echo "✅ README.md validation completed"

      - name: Check for broken internal links
        run: |
          echo "🔗 Checking for broken internal links..."
          # Simple check for markdown links that might be broken
          grep -r "\[.*\](\..*)" --include="*.md" . | while read -r line; do
            file=$(echo "$line" | cut -d: -f1)
            link=$(echo "$line" | sed -n 's/.*](\([^)]*\)).*/\1/p')
            if [ -n "$link" ] && [[ "$link" =~ ^\. ]]; then
              if [ ! -f "$link" ] && [ ! -d "$link" ]; then
                echo "⚠️ Potentially broken link in $file: $link"
              fi
            fi
          done || echo "✅ No obviously broken internal links found"

  performance:
    name: Performance Check
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install

      - name: Install dependencies
        run: uv sync --locked --all-extras --dev

      - name: Create performance test data
        run: |
          mkdir -p perf_test
          # Create sample Python files for performance testing
          for i in {1..50}; do
            cat > perf_test/test_file_$i.py << EOF
          """Test file $i for performance testing."""
          
          def function_$i():
              \"\"\"Example function $i.\"\"\"
              return "result_$i"
          
          class TestClass$i:
              \"\"\"Example class $i.\"\"\"
              def method_$i(self):
                  return "method_result_$i"
          EOF
          done

      - name: Run performance benchmark
        run: |
          echo "⚡ Running indexing performance test..."
          cd perf_test
          
          # Time the indexing operation
          start_time=$(date +%s)
          uv run chunkhound index . --no-watch
          end_time=$(date +%s)
          
          duration=$((end_time - start_time))
          echo "📊 Indexing 50 files took $duration seconds"
          
          # Test search performance
          start_time=$(date +%s)
          uv run python -c "
          import sys
          sys.path.insert(0, '..')  
          from chunkhound.database import Database
          
          db = Database()
          results = db.search_regex('function_')
          print(f'Found {len(results)} results')
          "
          end_time=$(date +%s)
          
          search_duration=$((end_time - start_time))
          echo "🔍 Regex search took $search_duration seconds"
        env:
          CHUNKHOUND_WATCH_ENABLED: "false"

  dependency-check:
    name: Dependency Analysis
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install

      - name: Install dependencies
        run: uv sync --locked --all-extras --dev

      - name: Check dependency licenses
        run: |
          echo "📜 Checking dependency licenses..."
          uv run pip-licenses --format=markdown --output-file=licenses.md || echo "⚠️ License check tool not available"
          
          if [ -f licenses.md ]; then
            echo "📋 Dependency licenses:"
            head -20 licenses.md
          fi

      - name: Check for outdated dependencies
        run: |
          echo "📦 Checking for outdated dependencies..."
          # Show current dependencies
          echo "Current dependencies:"
          uv tree
          
          # Note: uv doesn't have a direct equivalent to pip list --outdated
          # but we can show the dependency tree for manual review
          echo "✅ Dependency tree shown above for manual review"

      - name: Validate pyproject.toml
        run: |
          echo "⚙️ Validating pyproject.toml..."
          uv run python -c "
          import tomllib
          
          with open('pyproject.toml', 'rb') as f:
              data = tomllib.load(f)
          
          # Basic validation
          assert 'project' in data, 'Missing [project] section'
          assert 'name' in data['project'], 'Missing project name'
          assert 'version' in data['project'], 'Missing project version'
          assert 'dependencies' in data['project'], 'Missing dependencies'
          
          print('✅ pyproject.toml is valid')
          print(f'Project: {data[\"project\"][\"name\"]} v{data[\"project\"][\"version\"]}')
          print(f'Dependencies: {len(data[\"project\"][\"dependencies\"])} packages')
          "

  summary:
    name: Quality Summary
    runs-on: ubuntu-latest
    needs: [code-quality, security-scan, documentation, dependency-check]
    if: always()

    steps:
      - name: Quality Gate Summary
        run: |
          echo "## 🎯 Quality Assurance Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check job results
          if [ "${{ needs.code-quality.result }}" = "success" ]; then
            echo "✅ **Code Quality**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Code Quality**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.security-scan.result }}" = "success" ]; then
            echo "✅ **Security Scan**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Security Scan**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.documentation.result }}" = "success" ]; then
            echo "✅ **Documentation**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Documentation**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.dependency-check.result }}" = "success" ]; then
            echo "✅ **Dependencies**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Dependencies**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📊 **Overall Status**: Quality checks completed" >> $GITHUB_STEP_SUMMARY